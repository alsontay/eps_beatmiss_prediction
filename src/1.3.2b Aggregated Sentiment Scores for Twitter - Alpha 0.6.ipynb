{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4200,"status":"ok","timestamp":1668049305112,"user":{"displayName":"jonathan chee","userId":"05777634473293349957"},"user_tz":-480},"id":"kJUqQ83QTKFV","outputId":"6bfcb8ba-29ba-4c28-86a1-33f8eace5e4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (0.12.2)\n","Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.3.5)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (0.5.3)\n","Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.7.3)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels) (2022.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->statsmodels) (1.15.0)\n"]}],"source":["!pip install statsmodels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGfq6RG-TKFY"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Change Directory for Twitter Data\n","os.chdir('../data/alternative_alpha_datasets/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_LK0fTymjde"},"outputs":[],"source":["# Read CSV from Twitter sentiment analysis with alpha = 0.2\n","collated_df = pd.read_csv('Twitter_Sentiments.csv')\n","# Convert Earnings Date and Previous Earnings Date to datetime format\n","collated_df['Earnings Date'] = pd.to_datetime(collated_df['Earnings Date'], format = '%d/%m/%Y')\n","collated_df['Previous Earnings Date'] = pd.to_datetime(collated_df['Previous Earnings Date'], format = '%d/%m/%Y')\n","# Number of days between each quarter\n","collated_df['Delta'] = (collated_df['Earnings Date'] - collated_df['Previous Earnings Date']).dt.days\n","sentiment_df = collated_df[['Ticker', 'Earnings Date', 'Previous Earnings Date', 'Delta']].copy(deep = True)\n","sentiment_lst = sentiment_df.values.tolist()\n","\n","# Initialise column for Twitter sentiment analysis\n","collated_df['Twitter Sentiment'] = np.nan"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Change Directory for Twitter Data\n","os.chdir('../data/datafiles/twitter/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fBVqWiqblqHy"},"outputs":[],"source":["# Initialize a list to collect files not found\n","fnf = []\n","\n","# Loop through each stock per quarter in the Yahoo Finance list\n","for idx, ticker in enumerate(sentiment_lst):\n","    # Format the file name\n","    file = f'{ticker[0]}_Tweets_{ticker[4]}.csv'\n","    print(f'Initiating {idx}, {ticker[0]} {ticker[4]} collation...')\n","\n","    try:\n","        # Read the CSV file if it exists\n","        ticker_df = pd.read_csv(file)\n","    \n","        # Initialize a datetime series from the previous earnings date to the current earnings date\n","        tmp = np.zeros(ticker[3]+1)\n","        index = pd.date_range(start=ticker[2], end=ticker[1], freq='D')\n","        data = pd.Series(tmp, index)\n","\n","        # Convert date column to datetime format\n","        ticker_df['date'] = pd.to_datetime(ticker_df['date'], format = '%Y-%m-%d')\n","        ticker_df['collated_score'] = np.nan\n","\n","        # Calculcate a collated sentiment score for each date in the range\n","        # This score is a weighted average based on retweet count + 1 (to include the Tweet author in the count)\n","        # Retweet count + 1 serves as a measure of the number of people who agree with the sentiment\n","        for date in index:\n","            mask = ticker_df['date'] == date\n","            ticker_df.loc[mask,'collated_score'] = ticker_df.loc[mask, 'compound_score'] * ((ticker_df.loc[mask,'retweets_count']+1)/(ticker_df.loc[mask,'retweets_count'].sum()+ticker_df[mask].count()[0]))\n","            data[date] = ticker_df.loc[mask, 'collated_score'].sum()\n","\n","        # Perform a linear interpolation on the data such that the distribution is not affected\n","        data.interpolate(inplace=True)\n","\n","        # Perform exponential smoothing with alpha = 0.6 on the data\n","        # Heuristic initialization method is only available if the number of observations is more than 10\n","        try:\n","            model_fit = SimpleExpSmoothing(data, initialization_method=\"heuristic\").fit(\n","                smoothing_level=0.6, optimized=False\n","            )\n","        except:\n","            model_fit = SimpleExpSmoothing(data).fit(\n","                smoothing_level=0.6, optimized=False\n","            )\n","        \n","        # Obtain the final value as the aggregated sentiment score over the whole period\n","        model_fcast = model_fit.forecast(1)\n","        \n","        # Input the final aggregated sentiment score into the df to be saved\n","        collated_df.loc[idx, 'Twitter Sentiment'] = model_fcast[-1]\n","        print(f'Completed {idx}, {ticker[0]} {ticker[4]} collation.')\n","    \n","    # If file not found, append to fnf list\n","    except FileNotFoundError:\n","        print(f'File Not Found: {idx}, {file}')\n","        fnf.append((idx, ticker))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1RVJGXcMg2T"},"outputs":[],"source":["# Check for files not found - Should have only 1 observation\n","print(len(fnf), fnf)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8cfrmcxMg_M"},"outputs":[],"source":["# Check that there is only one missing value corresponding to the file not found\n","collated_df['Twitter Sentiment'].isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Caaod3l6rkqx"},"outputs":[],"source":["# Drop the redundant column\n","collated_df = collated_df.drop('Earnings Date STR', axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ERJxIpZPp-7R"},"outputs":[],"source":["# Uncomment this line if you wish to save to CSV\n","# collated_df.to_csv('Twitter_Sentiments_Alpha0.6.csv')"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"vscode":{"interpreter":{"hash":"5b020d37e2d2792244d38dc749b48635155a26318d10fe99dbb63be9f4ff243c"}}},"nbformat":4,"nbformat_minor":0}
